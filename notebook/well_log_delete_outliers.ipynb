{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51736b7",
   "metadata": {},
   "source": [
    "## 尝试剔除测井曲线的一些异常值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b6f23",
   "metadata": {},
   "source": [
    "除了使用统计方法（如 3σ 法则、箱线图）识别离群点外，我们还可以根据测井原理和地质知识，预先定义一些不合理的数值范围。\n",
    "\n",
    "以下是一些可以先验地认为是异常值的建议和理由：\n",
    "\n",
    "1.  **GR (自然伽马, API)**\n",
    "\n",
    "    - **异常值:** `< 0`\n",
    "    - **理由:** GR 测量的是地层的自然放射性强度，其物理意义决定了它不可能是负值。出现负值通常是由于仪器刻度或数据处理过程中的基线漂移导致的错误。\n",
    "\n",
    "2.  **DEN (或 RHOB, 密度, g/cm³)**\n",
    "\n",
    "    - **异常值:** `< 1.0`\n",
    "    - **理由:**\n",
    "      - 密度值小于 1.0 g/cm³ (水的密度) 是不符合物理规律的，除非在极特殊情况下（如充气井眼）。这通常表示井眼严重扩径（washout），导致密度工具测量到的是密度较低的钻井液而不是地层。\n",
    "\n",
    "3.  **DT (或 AC, 声波时差, us/ft)**\n",
    "\n",
    "    - **异常值:** `< 40` 或 `> 200`\n",
    "    - **理由:**\n",
    "      - 声波时差反映了声波穿过单位距离地层所需的时间。即使是完全致密、无孔隙的岩石（如石英，时差约 55.5 us/ft；白云石，约 43.5 us/ft），其时差值也很难低于 40 us/ft。低于这个值通常是所谓的“跳周”（cycle skipping）现象，是声波仪器在复杂井眼条件下的一种典型错误。\n",
    "      - 大于 200 us/ft 的值表示地层非常疏松或声速极慢。虽然钻井液的时差大约在 189 us/ft，井眼垮塌区域可能出现高值，但持续高于 200 us/ft 的数据点很可能是异常的，特别是在非欠压实地层中。\n",
    "\n",
    "4.  **CAL (井径, in)**\n",
    "\n",
    "    - **异常值:** 小于钻头尺寸 (e.g., `< 8.5`) 或 远大于钻头尺寸 (e.g., `> 16`)\n",
    "    - **理由:**\n",
    "      - 井径曲线反映了井眼的尺寸。它的值理论上不应小于钻井时使用的钻头尺寸（例如，在 8.5 英寸的井眼中，CAL 不应小于 8.5）。小于钻头尺寸的值可能表示仪器问题或井壁上形成了厚厚的泥饼。\n",
    "      - 远大于钻头尺寸的值表示井眼严重扩径或存在大的溶洞。虽然扩径是正常现象，但一个过大的阈值（如 16 英寸）可以帮助我们识别那些可能对其他测井响应产生严重影响的层段。\n",
    "\n",
    "5.  **LLD (深侧向电阻率, ohm.m)**\n",
    "    - **异常值:** `< 0.1` 或 `> 2000`\n",
    "    - **理由:**\n",
    "      - 电阻率不应为负值，任何负值都是错误。极低的值（如小于 0.1 ohm.m）虽然在某些高矿化度盐水层中可能出现，但在常规油气藏勘探中非常罕见，通常表示仪器短路或数据错误。\n",
    "      - 电阻率可以非常高（如在致密碳酸盐岩、煤层、油气层中）。设置一个上限（如 2000 ohm.m）主要是为了处理仪器超出量程或“无穷大”的情况。在对数坐标下，这些极高值会严重影响可视化和统计分析，通常会将它们限制（clip）在一个合理的最高值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e400ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import lasio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 设置中文字体支持\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\", \"DejaVu Sans\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ce040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义路径\n",
    "las_folder = \"../data/vertical_well_truncated_las\"\n",
    "output_folder = \"../data/vertical_well_las_delete_outliers\"\n",
    "\n",
    "# 创建输出文件夹\n",
    "output_path = Path(output_folder)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 定义异常值规则\n",
    "ANOMALY_RULES = {\n",
    "    \"GR\": {\"min\": 0, \"max\": None, \"description\": \"GR不能为负值（物理意义）\"},\n",
    "    \"DEN\": {\"min\": 1.0, \"max\": 3.0, \"description\": \"密度小于1.0表示井眼扩径或钻井液，大于3.0不合理\"},\n",
    "    \"RHOB\": {\"min\": 1.0, \"max\": 3.0, \"description\": \"密度小于1.0表示井眼扩径或钻井液，大于3.0不合理\"},\n",
    "    \"DT\": {\"min\": 40, \"max\": 200, \"description\": \"小于40为跳周现象，大于200表示极疏松地层或异常\"},\n",
    "    \"AC\": {\"min\": 40, \"max\": 200, \"description\": \"小于40为跳周现象,大于200表示极疏松地层或异常\"},\n",
    "    \"CAL\": {\"min\": 8.5, \"max\": 16.0, \"description\": \"井径不应小于钻头尺寸，远大于钻头尺寸表示严重扩径\"},\n",
    "    \"CALI\": {\"min\": 8.5, \"max\": 16.0, \"description\": \"井径不应小于钻头尺寸，远大于钻头尺寸表示严重扩径\"},\n",
    "    \"LLD\": {\"min\": 0.1, \"max\": 2000, \"description\": \"极低值表示仪器短路，极高值需要截断\"},\n",
    "    \"LLD1\": {\"min\": 0.1, \"max\": 2000, \"description\": \"极低值表示仪器短路，极高值需要截断\"},\n",
    "}\n",
    "\n",
    "\n",
    "def detect_anomalies(data: np.ndarray, min_val: float = None, max_val: float = None) -> np.ndarray:  # type: ignore\n",
    "    \"\"\"\n",
    "    检测异常值\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : np.ndarray\n",
    "        测井数据\n",
    "    min_val : float\n",
    "        最小合理值\n",
    "    max_val : float\n",
    "        最大合理值\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mask : np.ndarray\n",
    "        异常值掩码（True表示异常）\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    # 检测NaN\n",
    "    mask |= np.isnan(data)\n",
    "\n",
    "    # 检测无穷大\n",
    "    mask |= np.isinf(data)\n",
    "\n",
    "    # 检测超出范围的值\n",
    "    if min_val is not None:\n",
    "        mask |= data < min_val\n",
    "\n",
    "    if max_val is not None:\n",
    "        mask |= data > max_val\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def apply_statistical_filter(data: np.ndarray, sigma: float = 3.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    应用3σ法则检测离群点\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : np.ndarray\n",
    "        测井数据\n",
    "    sigma : float\n",
    "        标准差倍数，默认3\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mask : np.ndarray\n",
    "        离群点掩码（True表示离群）\n",
    "    \"\"\"\n",
    "    # 排除NaN和Inf\n",
    "    valid_data = data[~np.isnan(data) & ~np.isinf(data)]\n",
    "\n",
    "    if len(valid_data) == 0:\n",
    "        return np.zeros(len(data), dtype=bool)\n",
    "\n",
    "    mean = np.mean(valid_data)\n",
    "    std = np.std(valid_data)\n",
    "\n",
    "    mask = np.abs(data - mean) > (sigma * std)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_curve_mnemonic(las: lasio.LASFile, possible_names: list) -> str:\n",
    "    \"\"\"\n",
    "    根据可能的名称列表查找曲线\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    las : lasio.LASFile\n",
    "        LAS文件对象\n",
    "    possible_names : list\n",
    "        可能的曲线名称列表\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mnemonic : str or None\n",
    "        找到的曲线名称\n",
    "    \"\"\"\n",
    "    curve_mnemonics = [c.mnemonic for c in las.curves]\n",
    "\n",
    "    for name in possible_names:\n",
    "        if name in curve_mnemonics:\n",
    "            return name\n",
    "\n",
    "    return None  # type: ignore\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"测井曲线异常值处理\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n异常值规则:\")\n",
    "for curve, rule in ANOMALY_RULES.items():\n",
    "    min_str = f\"{rule['min']}\" if rule[\"min\"] is not None else \"无限制\"\n",
    "    max_str = f\"{rule['max']}\" if rule[\"max\"] is not None else \"无限制\"\n",
    "    print(f\"  {curve:8s}: [{min_str:8s}, {max_str:8s}] - {rule['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e780bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有LAS文件\n",
    "input_path = Path(las_folder)\n",
    "las_files = list(input_path.glob(\"*.las\"))\n",
    "las_files = list(set(las_files))\n",
    "las_files.sort()\n",
    "\n",
    "if not las_files:\n",
    "    print(f\"\\n在 {las_folder} 中未找到LAS文件\")\n",
    "else:\n",
    "    print(f\"\\n找到 {len(las_files)} 个LAS文件\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 统计信息\n",
    "    processing_stats = []\n",
    "    success_count = 0\n",
    "    failed_files = []\n",
    "\n",
    "    for las_file in las_files:\n",
    "        well_name = las_file.stem\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"处理井: {well_name}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        try:\n",
    "            # 读取LAS文件\n",
    "            las = lasio.read(las_file, mnemonic_case=\"upper\")\n",
    "\n",
    "            # 统计该井的异常值信息\n",
    "            well_stats = {\"Well\": well_name}\n",
    "\n",
    "            # 创建新的LAS对象\n",
    "            new_las = lasio.LASFile()\n",
    "            new_las.version = las.version\n",
    "            new_las.well = las.well\n",
    "            new_las.params = las.params\n",
    "            new_las.other = las.other\n",
    "\n",
    "            # 处理每条曲线\n",
    "            for curve in las.curves:\n",
    "                mnemonic = curve.mnemonic\n",
    "                data = curve.data.copy()\n",
    "                original_count = len(data)\n",
    "\n",
    "                # 检查是否有对应的异常值规则\n",
    "                rule = ANOMALY_RULES.get(mnemonic)\n",
    "\n",
    "                if rule is not None:\n",
    "                    print(f\"\\n曲线: {mnemonic}\")\n",
    "                    print(f\"  原始数据点数: {original_count}\")\n",
    "\n",
    "                    # 先验异常值检测\n",
    "                    prior_mask = detect_anomalies(data, min_val=rule[\"min\"], max_val=rule[\"max\"])\n",
    "                    prior_anomaly_count = np.sum(prior_mask)\n",
    "                    prior_anomaly_pct = (prior_anomaly_count / original_count) * 100\n",
    "\n",
    "                    print(f\"  先验异常值: {prior_anomaly_count} ({prior_anomaly_pct:.2f}%)\")\n",
    "\n",
    "                    # 3σ统计异常值检测（仅对非先验异常值应用）\n",
    "                    valid_data = data[~prior_mask]\n",
    "                    if len(valid_data) > 0:\n",
    "                        # 对整个数据应用3σ检测\n",
    "                        statistical_mask = apply_statistical_filter(data, sigma=3.0)\n",
    "                        # 但只统计非先验异常的部分\n",
    "                        statistical_only_mask = statistical_mask & ~prior_mask\n",
    "                        statistical_anomaly_count = np.sum(statistical_only_mask)\n",
    "                        statistical_anomaly_pct = (statistical_anomaly_count / original_count) * 100\n",
    "\n",
    "                        print(f\"  统计离群值(3σ): {statistical_anomaly_count} ({statistical_anomaly_pct:.2f}%)\")\n",
    "\n",
    "                        # 合并所有异常值\n",
    "                        total_mask = prior_mask | statistical_mask\n",
    "                    else:\n",
    "                        total_mask = prior_mask\n",
    "                        statistical_anomaly_count = 0\n",
    "                        statistical_anomaly_pct = 0.0\n",
    "\n",
    "                    total_anomaly_count = np.sum(total_mask)\n",
    "                    total_anomaly_pct = (total_anomaly_count / original_count) * 100\n",
    "\n",
    "                    print(f\"  总异常值: {total_anomaly_count} ({total_anomaly_pct:.2f}%)\")\n",
    "\n",
    "                    # 将异常值设为NaN\n",
    "                    data[total_mask] = np.nan\n",
    "\n",
    "                    valid_count = np.sum(~np.isnan(data))\n",
    "                    print(f\"  有效数据点数: {valid_count}\")\n",
    "\n",
    "                    # 记录统计信息（数量和百分比）\n",
    "                    well_stats[f\"{mnemonic}_Points\"] = original_count  # type: ignore\n",
    "                    well_stats[f\"{mnemonic}_Prior_Count\"] = prior_anomaly_count\n",
    "                    well_stats[f\"{mnemonic}_Prior_Pct\"] = prior_anomaly_pct\n",
    "                    well_stats[f\"{mnemonic}_Statistical_Count\"] = statistical_anomaly_count  # type: ignore\n",
    "                    well_stats[f\"{mnemonic}_Statistical_Pct\"] = statistical_anomaly_pct  # type: ignore\n",
    "                    well_stats[f\"{mnemonic}_Total_Count\"] = total_anomaly_count  # type: ignore\n",
    "                    well_stats[f\"{mnemonic}_Total_Pct\"] = total_anomaly_pct  # type: ignore\n",
    "                    well_stats[f\"{mnemonic}_Valid_Count\"] = valid_count\n",
    "\n",
    "                else:\n",
    "                    # 对于没有先验规则的曲线，只进行基本的NaN和Inf检测\n",
    "                    basic_mask = np.isnan(data) | np.isinf(data)\n",
    "                    basic_anomaly_count = np.sum(basic_mask)\n",
    "\n",
    "                    if basic_anomaly_count > 0:\n",
    "                        print(f\"\\n曲线: {mnemonic}\")\n",
    "                        print(f\"  原始数据点数: {original_count}\")\n",
    "                        print(f\"  NaN/Inf异常: {basic_anomaly_count}\")\n",
    "                        data[basic_mask] = np.nan\n",
    "\n",
    "                # 添加处理后的曲线\n",
    "                new_las.append_curve(\n",
    "                    mnemonic=curve.mnemonic, data=data, unit=curve.unit, descr=curve.descr, value=curve.value\n",
    "                )\n",
    "\n",
    "            # 保存处理后的文件\n",
    "            output_file = output_path / las_file.name\n",
    "            new_las.write(str(output_file), version=2.0)\n",
    "\n",
    "            print(f\"\\n✓ 成功处理并保存到 {output_file.name}\")\n",
    "            success_count += 1\n",
    "\n",
    "            # 保存统计信息\n",
    "            processing_stats.append(well_stats)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ 处理失败: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "            failed_files.append((well_name, str(e)))\n",
    "\n",
    "    # 保存处理统计信息\n",
    "    if processing_stats:\n",
    "        stats_df = pd.DataFrame(processing_stats)\n",
    "        stats_file = \"output/processing_statistics.xlsx\"\n",
    "        stats_df.to_excel(stats_file, index=False)\n",
    "        print(f\"\\n统计信息已保存到: {stats_file}\")\n",
    "\n",
    "    # 输出总体统计\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"处理完成！\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"成功: {success_count}/{len(las_files)}\")\n",
    "\n",
    "    if failed_files:\n",
    "        print(f\"\\n失败的文件:\")\n",
    "        for filename, error in failed_files:\n",
    "            print(f\"  - {filename}: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c04d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化统计结果\n",
    "if processing_stats:\n",
    "    stats_df = pd.DataFrame(processing_stats)\n",
    "\n",
    "    # 统计各曲线的异常值情况\n",
    "    curves_to_analyze = [\"GR\", \"DEN\", \"RHOB\", \"DT\", \"AC\", \"CAL\", \"CALI\", \"LLD\", \"LLD1\"]\n",
    "\n",
    "    # 提取异常值百分比数据用于热力图\n",
    "    anomaly_pct_data = {}\n",
    "    for curve in curves_to_analyze:\n",
    "        pct_col = f\"{curve}_Total_Pct\"\n",
    "        if pct_col in stats_df.columns:\n",
    "            anomaly_pct_data[curve] = stats_df[pct_col].fillna(0).values\n",
    "\n",
    "    # 提取异常值数量数据用于柱状图\n",
    "    anomaly_counts = {}\n",
    "    for curve in curves_to_analyze:\n",
    "        count_col = f\"{curve}_Total_Count\"\n",
    "        if count_col in stats_df.columns:\n",
    "            anomaly_counts[curve] = stats_df[count_col].fillna(0).values\n",
    "\n",
    "    # 创建图表 (1行2列布局)\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    gs = fig.add_gridspec(1, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # 1. 热力图：各井各曲线异常值占比\n",
    "    if anomaly_pct_data:\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        pct_df = pd.DataFrame(anomaly_pct_data, index=stats_df[\"Well\"])\n",
    "        pct_df_filtered = pct_df.loc[:, (pct_df > 0).any()]\n",
    "\n",
    "        if len(pct_df_filtered.columns) > 0:\n",
    "            im = ax1.imshow(pct_df_filtered.values, cmap=\"YlOrRd\", aspect=\"auto\", vmin=0, vmax=100)\n",
    "            ax1.set_xticks(range(len(pct_df_filtered.columns)))\n",
    "            ax1.set_xticklabels(pct_df_filtered.columns, fontsize=11, fontweight=\"bold\")\n",
    "            ax1.set_yticks(range(len(pct_df_filtered.index)))\n",
    "            ax1.set_yticklabels([name[:15] for name in pct_df_filtered.index], fontsize=9)\n",
    "            ax1.set_title(\"各井各曲线异常值占比热力图 (%)\", fontweight=\"bold\", fontsize=14, pad=15)\n",
    "            ax1.set_xlabel(\"曲线类型\", fontsize=12, fontweight=\"bold\")\n",
    "            ax1.set_ylabel(\"井名\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "            # 添加颜色条\n",
    "            cbar = plt.colorbar(im, ax=ax1, fraction=0.046, pad=0.04)\n",
    "            cbar.set_label(\"异常值占比 (%)\", rotation=270, labelpad=20, fontsize=11)\n",
    "\n",
    "            # 在热力图上标注数值\n",
    "            for i in range(len(pct_df_filtered.index)):\n",
    "                for j in range(len(pct_df_filtered.columns)):\n",
    "                    value = pct_df_filtered.values[i, j]\n",
    "                    # if value > 0:\n",
    "                    text_color = \"white\" if value > 50 else \"black\"\n",
    "                    ax1.text(\n",
    "                        j,\n",
    "                        i,\n",
    "                        f\"{value:.1f}\",\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        color=text_color,\n",
    "                        fontsize=8,\n",
    "                        fontweight=\"bold\",\n",
    "                    )\n",
    "\n",
    "    # 2. 堆叠柱状图：各井异常值数量分解\n",
    "    if anomaly_counts:\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        counts_df = pd.DataFrame(anomaly_counts, index=stats_df[\"Well\"])\n",
    "        counts_df_filtered = counts_df.loc[:, (counts_df > 0).any()]\n",
    "\n",
    "        if len(counts_df_filtered.columns) > 0:\n",
    "            counts_df_filtered.plot(kind=\"bar\", stacked=True, ax=ax2, colormap=\"tab10\", width=0.8)\n",
    "            ax2.set_title(\"各井异常值数量分解\", fontweight=\"bold\", fontsize=13)\n",
    "            ax2.set_xlabel(\"井名\", fontsize=11)\n",
    "            ax2.set_ylabel(\"异常值数量\", fontsize=11)\n",
    "            ax2.legend(title=\"曲线\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", fontsize=9)\n",
    "            ax2.set_xticklabels([name[:12] for name in counts_df_filtered.index], rotation=45, ha=\"right\", fontsize=9)\n",
    "            ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\"测井曲线异常值统计分析\", fontsize=16, fontweight=\"bold\", y=0.98)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图表\n",
    "    fig_file = \"output/anomaly_statistics.png\"\n",
    "    plt.savefig(fig_file, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"\\n统计图表已保存到: {fig_file}\")\n",
    "\n",
    "    # 输出统计摘要\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"异常值统计摘要\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if anomaly_pct_data:\n",
    "        pct_df = pd.DataFrame(anomaly_pct_data, index=stats_df[\"Well\"])\n",
    "        print(\"\\n各曲线平均异常值占比:\")\n",
    "        for col in pct_df.columns:\n",
    "            if pct_df[col].sum() > 0:\n",
    "                avg_pct = pct_df[col].mean()\n",
    "                max_pct = pct_df[col].max()\n",
    "                max_well = pct_df[col].idxmax()\n",
    "                print(f\"  {col:8s}: 平均 {avg_pct:5.2f}%  最大 {max_pct:5.2f}% ({max_well})\")\n",
    "\n",
    "        print(\"\\n异常值占比最高的5口井:\")\n",
    "        well_avg = pct_df.mean(axis=1).sort_values(ascending=False).head(5)\n",
    "        for well, avg in well_avg.items():\n",
    "            print(f\"  {well:20s}: {avg:5.2f}%\")\n",
    "\n",
    "    if anomaly_counts:\n",
    "        counts_df = pd.DataFrame(anomaly_counts, index=stats_df[\"Well\"])\n",
    "        counts_df_filtered = counts_df.loc[:, (counts_df > 0).any()]\n",
    "        if len(counts_df_filtered.columns) > 0:\n",
    "            print(\"\\n各曲线总异常值数量:\")\n",
    "            for col in counts_df_filtered.columns:\n",
    "                total_count = counts_df_filtered[col].sum()\n",
    "                max_count = counts_df_filtered[col].max()\n",
    "                max_well = counts_df_filtered[col].idxmax()\n",
    "                print(f\"  {col:8s}: 总计 {total_count:6.0f}  最大 {max_count:6.0f} ({max_well})\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transform2021_devito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
