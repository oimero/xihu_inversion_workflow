{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import 数据导入\n",
    "\n",
    "In this notebook we present how the data should be imported in order to be used with the automatic seismic to well tie package _wtie_. Instructions to install the package can be found in the README.md file.\n",
    "在本 notebook 中，我们展示了如何导入数据以便与自动地震到井标定包 _wtie_ 一起使用。安装该包的说明可以在 README.md 文件中找到。\n",
    "\n",
    "In order to use the package with your own data, you must first implement small python utilities to load the data from their original format and store it into _wtie_'s internal format. Example functions can be found in the file _wtie/utils/datasets/tutorial.py_. In the following, we show how to do so step by step.\n",
    "为了将该包用于您自己的数据，您必须首先实现一些小的 python 实用程序，以从其原始格式加载数据并将其存储到 _wtie_ 的内部格式中。示例函数可以在文件 _wtie/utils/datasets/tutorial.py_ 中找到。下面，我们将逐步展示如何操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages 加载包\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import lasio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import segyio\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from wtie import grid, viz\n",
    "from wtie.processing.logs import interpolate_nans\n",
    "\n",
    "# uncomment if your browser supports it\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 数据集\n",
    "\n",
    "In this tutorial we work on data from the Well 159-19A of the open [Volve dataset](https://www.equinor.com/en/what-we-do/digitalisation-in-our-dna/volve-field-data-village-download.html). Data is saved in the folder **data/tutorial**.\n",
    "在本教程中，我们使用来自开放的 [Volve 数据集](https://www.equinor.com/en/what-we-do/digitalisation-in-our-dna/volve-field-data-village-download.html) 中 159-19A 井的数据。数据保存在 **data/tutorial** 文件夹中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "folder = Path(\"../data/tutorial/Volve\")\n",
    "trajectory_path = folder / \"volve_path_15_9-19_A.txt\"\n",
    "table_path = folder / \"volve_checkshot_15_9_19A.txt\"\n",
    "logs_path = folder / \"volve_159-19A_LFP.las\"\n",
    "seis_path = folder / \"volve_15_9_19A_gather.sgy\"\n",
    "\n",
    "assert folder.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data objects 数据对象\n",
    "\n",
    "The package implements a series of data objects that must be employed in order to ensure compatibility with the various methods. All classes are present in the _grid.py_ file (`from wtie import grid`). Each class follows a similar logic, and must be provided with the following information:\n",
    "该包实现了一系列数据对象，必须使用这些对象以确保与各种方法的兼容性。所有类都存在于 _grid.py_ 文件中 (`from wtie import grid`)。每个类都遵循相似的逻辑，并且必须提供以下信息：\n",
    "\n",
    "- the _data values_ (e.g. seismic or log amplitudes).\n",
    "- _数据值_ (例如地震或测井振幅)。\n",
    "- the _data basis_ (e.g. from 1.2 to 1.9s with a 0.001s sampling rate).\n",
    "- _数据基准_ (例如从 1.2 到 1.9 秒，采样率为 0.001 秒)。\n",
    "- the _basis type_ (e.g. two-way-time or measured depth).\n",
    "- _基准类型_ (例如双程时或测量深度)。\n",
    "  The different basis types supported can be found in `grid.EXISTING_BASIS_TYPES`. Units of the basis must be as writen (i.e. meters, seconds and degrees).\n",
    "  支持的不同基准类型可以在 `grid.EXISTING_BASIS_TYPES` 中找到。基准的单位必须按规定书写 (即米、秒和度)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(grid.EXISTING_BASIS_TYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ 这些是地球物理和测井领域中常用的基准类型（坐标轴）及其单位，含义如下：\n",
    "\n",
    "- **`'angle': 'Angle [°]'`**: **角度**，单位是度(°)。通常用于叠前地震数据，表示地震波的入射角。\n",
    "- **`'md': 'MD (kb) [m]'`**: **测量深度 (Measured Depth)**，单位是米(m)。指沿着井眼轨迹从井口参考点（通常是转盘衬套 Kelly Bushing, kb）开始测量的深度。\n",
    "- **`'tlag': 'Lag [s]'`**: **时间延迟 (Time Lag)**，单位是秒(s)。通常指两个时间序列（如合成记录和实际地震数据）之间的时移量。\n",
    "- **`'tvdkb': 'TVDKB [m]'`**: **从转盘衬套算起的真垂直深度 (True Vertical Depth from Kelly Bushing)**，单位是米(m)。指井下某点到井口参考点（KB）的垂直距离。\n",
    "- **`'tvdss': 'TVDSS (MSL) [m]'`**: **海平面以下的真垂直深度 (True Vertical Depth Sub-Sea)**，单位是米(m)。指井下某点到平均海平面（Mean Sea Level, MSL）的垂直距离。\n",
    "- **`'twt': 'TWT [s]'`**: **双程旅行时 (Two-Way Time)**，单位是秒(s)。指地震波从地表到地下反射界面再返回到地表所用的时间。\n",
    "- **`'zlag': 'Lag [m]'`**: **深度延迟 (Depth Lag)**，单位是米(m)。指两个深度序列之间的深度差或位移。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import well logs 导入井测井\n",
    "\n",
    "We use the [lasio](https://github.com/kinverarity1/lasio) library to read the las file, read the data in a pandas [dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) and store it into the custom objects `grid.Log` and `grid.LogSet`.\n",
    "我们使用 [lasio](https://github.com/kinverarity1/lasio) 库来读取 las 文件，将数据读入 pandas [dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) 中，并将其存储到自定义对象 `grid.Log` 和 `grid.LogSet` 中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_logs = lasio.read(logs_path)\n",
    "las_logs = las_logs.df()\n",
    "las_logs.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = las_logs[\"LFP_VP\"].index\n",
    "vp = las_logs[\"LFP_VP\"].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(basis, vp)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logs are recorded in _measured depth_, according to the `grid.EXISTING_BASIS_TYPES` we therefore need to set the `basis_type` variable as `'md'`.\n",
    "测井是按 _测量深度_ 记录的，根据 `grid.EXISTING_BASIS_TYPES`，我们因此需要将 `basis_type` 变量设置为 `'md'`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vp = grid.Log(las_logs[\"LFP_VP\"].values, las_logs[\"LFP_VP\"].index, \"md\", name=\"Vp\")\n",
    "viz.plot_trace(Vp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_logs(file_path: str) -> grid.LogSet:\n",
    "    file_path = Path(file_path)  # type: ignore\n",
    "    assert file_path.name == \"volve_159-19A_LFP.las\"  # type: ignore\n",
    "\n",
    "    # Read file\n",
    "    las_logs = lasio.read(file_path)\n",
    "    las_logs = las_logs.df()\n",
    "\n",
    "    # Select some logs, there are more, we only load the follwoing\n",
    "    # must at least contain the keys 'Vp' for acoustic velocity\n",
    "    # and 'Rho' for the bulk density. 'Vs', for shear velocity, must also\n",
    "    # be imported if one whishes to perform a prestack well-tie.\n",
    "    # Other logs are optional.\n",
    "    log_dict = {}\n",
    "\n",
    "    log_dict[\"Vp\"] = grid.Log(las_logs[\"LFP_VP\"].values, las_logs[\"LFP_VP\"].index, \"md\", name=\"Vp\")\n",
    "    log_dict[\"Vs\"] = grid.Log(las_logs[\"LFP_VS\"].values, las_logs[\"LFP_VS\"].index, \"md\", name=\"Vs\")\n",
    "\n",
    "    # Density contains some NaNs, I fill them with linear interpolation.\n",
    "    log_dict[\"Rho\"] = grid.Log(\n",
    "        interpolate_nans(las_logs[\"LFP_RHOB\"].values),  # type: ignore\n",
    "        las_logs[\"LFP_RHOB\"].index,\n",
    "        \"md\",\n",
    "        name=\"Rho\",\n",
    "    )\n",
    "\n",
    "    log_dict[\"GR\"] = grid.Log(interpolate_nans(las_logs[\"LFP_GR\"].values), las_logs[\"LFP_VP\"].index, \"md\")  # type: ignore\n",
    "    log_dict[\"Cali\"] = grid.Log(las_logs[\"LFP_CALI\"].values, las_logs[\"LFP_VP\"].index, \"md\")\n",
    "\n",
    "    return grid.LogSet(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logset_md = import_logs(logs_path)  # md is for measured depth  # type: ignore\n",
    "print(logset_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_logset(logset_md);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Seismic 导入地震数据\n",
    "\n",
    "We use the package [segyio](https://github.com/equinor/segyio) to read the segy and strore the data in the `grid.Seismic` and `grid.PreStackSeismic` objects. The provided segy is a composite angle gather extracted along the well path.\n",
    "我们使用 [segyio](https://github.com/equinor/segyio) 包来读取 segy 文件，并将数据存储在 `grid.Seismic` 和 `grid.PreStackSeismic` 对象中。提供的 segy 文件是沿井路径提取的复合角度道集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with segyio.open(seis_path, \"r\") as f:\n",
    "    print(f.samples.size)  # number of time samples  # type: ignore\n",
    "    print(f.ilines)\n",
    "    print(f.xlines)\n",
    "    print(f.offsets)  # these are actually angles, from 0 to 45 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_seismic(file_path: str) -> grid.Seismic:\n",
    "    file_path = Path(file_path)  # type: ignore\n",
    "    assert file_path.name == \"volve_15_9_19A_gather.sgy\"  # type: ignore\n",
    "\n",
    "    with segyio.open(file_path, \"r\") as f:\n",
    "        _twt = f.samples / 1000  # two-way-time in seconds  # type: ignore\n",
    "        _seis = np.squeeze(segyio.tools.cube(f))  # 2D (angles, samples)\n",
    "\n",
    "    # stacking the first 8 angles\n",
    "    _seis = np.sum(_seis[:8, :], axis=0)\n",
    "\n",
    "    return grid.Seismic(_seis, _twt, \"twt\", name=\"Real seismic\")\n",
    "\n",
    "\n",
    "def import_prestack_seismic(file_path: str) -> grid.PreStackSeismic:\n",
    "    \"\"\"For simplicity, only angle gathers are allowed.\"\"\"\n",
    "    file_path = Path(file_path)  # type: ignore\n",
    "    assert file_path.name == \"volve_15_9_19A_gather.sgy\"  # type: ignore\n",
    "\n",
    "    with segyio.open(file_path, \"r\") as f:\n",
    "        _twt = f.samples / 1000  # type: ignore\n",
    "        _seis = np.squeeze(segyio.tools.cube(f))\n",
    "        _angles = f.offsets\n",
    "\n",
    "    seismic = []\n",
    "    for i, theta in enumerate(_angles):  # type: ignore\n",
    "        seismic.append(grid.Seismic(_seis[i, :], _twt, \"twt\", theta=theta))\n",
    "\n",
    "    return grid.PreStackSeismic(seismic, name=\"Real gather\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seismic = import_seismic(seis_path)  # type: ignore\n",
    "gather = import_prestack_seismic(seis_path)  # type: ignore\n",
    "viz.plot_trace(seismic)\n",
    "viz.plot_prestack_trace_as_pixels(gather, figsize=(7, 9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well trajectory 井轨迹\n",
    "\n",
    "We store the well trajectory in the `grid.WellPath` object.\n",
    "我们将井轨迹存储在 `grid.WellPath` 对象中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.WellPath.__doc__)\n",
    "print(grid.WellPath.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_well_path(file_path: str) -> grid.WellPath:\n",
    "    file_path = Path(file_path)  # type: ignore\n",
    "    assert file_path.name == \"volve_path_15_9-19_A.txt\"  # type: ignore\n",
    "\n",
    "    _wp = pd.read_csv(file_path, header=None, delimiter=r\"\\s+\", names=(\"MD (kb) [m]\", \"Inclination\", \"Azimuth\"))\n",
    "\n",
    "    kb = 25  # meters\n",
    "\n",
    "    _tvd = grid.WellPath.get_tvdkb_from_inclination(\n",
    "        _wp.loc[:, \"MD (kb) [m]\"].values,  # type: ignore\n",
    "        _wp.loc[:, \"Inclination\"].values[:-1],  # type: ignore\n",
    "    )\n",
    "    _tvd = grid.WellPath.tvdkb_to_tvdss(_tvd, kb)\n",
    "\n",
    "    return grid.WellPath(md=_wp.loc[:, \"MD (kb) [m]\"].values, tvdss=_tvd, kb=kb)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellpath = import_well_path(trajectory_path)  # type: ignore\n",
    "viz.plot_wellpath(wellpath);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Depth relation table 时深关系表\n",
    "\n",
    "We strore the depth-time relation table to a `grid.TimeDepthTable` object.\n",
    "我们将时深关系表存储到 `grid.TimeDepthTable` 对象中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.TimeDepthTable.__doc__)\n",
    "print(grid.TimeDepthTable.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_time_depth_table(file_path: str) -> grid.TimeDepthTable:\n",
    "    file_path = Path(file_path)  # type: ignore\n",
    "    assert file_path.name == \"volve_checkshot_15_9_19A.txt\"  # type: ignore\n",
    "\n",
    "    _td = pd.read_csv(\n",
    "        file_path, header=None, delimiter=r\"\\s+\", skiprows=[0], names=(\"Curve Name\", \"TVDBTDD\", \"TVDKB\", \"TVDSS\", \"TWT\")\n",
    "    )\n",
    "\n",
    "    _twt = _td.loc[:, \"TWT\"].values / 1000  # seconds  # type: ignore\n",
    "    _tvdss = np.abs(_td.loc[:, \"TVDSS\"].values)  # meters  # type: ignore\n",
    "\n",
    "    return grid.TimeDepthTable(twt=_twt, tvdss=_tvdss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "td_table = import_time_depth_table(table_path)  # type: ignore\n",
    "viz.plot_td_table(td_table);"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "wtie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
